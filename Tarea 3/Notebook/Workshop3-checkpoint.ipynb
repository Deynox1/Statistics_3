{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "082245eb-3838-4302-828f-c5170971f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afdc9d0-dc09-421d-8d0c-4fe9d096c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = './plantstrain'\n",
    "test_data_dir = './plantstest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8177d3-bf0a-4e66-97ac-c86ae9dce053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listas para almacenar imágenes y etiquetas de entrenamiento y prueba\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# Obtener la lista de subcarpetas para entrenamiento (cada subcarpeta representa una clase)\n",
    "train_subfolders = [f.path for f in os.scandir(train_data_dir) if f.is_dir()]\n",
    "\n",
    "# Leer imágenes de entrenamiento y asignar etiquetas\n",
    "for subfolder in train_subfolders:\n",
    "    class_label = subfolder.split(os.path.sep)[-1]\n",
    "    image_files = glob.glob(os.path.join(subfolder, '*.png'))\n",
    "    for img_path in image_files:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            # Aplicar interpolación durante el redimensionamiento\n",
    "            img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)  \n",
    "            train_images.append(img)\n",
    "            train_labels.append(class_label)\n",
    "\n",
    "# Obtener la lista de subcarpetas en el directorio de prueba\n",
    "test_subfolders = [f.path for f in os.scandir(test_data_dir) if f.is_dir()]\n",
    "\n",
    "# Leer imágenes de prueba y asignar etiquetas\n",
    "for subfolder in test_subfolders:\n",
    "    image_files = glob.glob(os.path.join(subfolder, '*.png'))\n",
    "    for img_path in image_files:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            # Aplicar interpolación durante el redimensionamiento\n",
    "            img = cv2.resize(img, (299, 299), interpolation=cv2.INTER_CUBIC)  \n",
    "            test_images.append(img)\n",
    "            test_labels.append(os.path.basename(subfolder))\n",
    "            \n",
    "# Convertir las listas de imágenes y etiquetas en matrices numpy\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Codificar etiquetas de entrenamiento como números\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Normalizar los píxeles al rango [0, 1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d7e87-2c35-47b7-b29f-4778162b2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels_encoded, test_size=0.15, random_state=2)\n",
    "\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=11)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=11)\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=5, verbose=1, mode='max', min_lr=1e-5)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6, verbose=1)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "input_shape = (299,299,3)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=180,  # Rango de grados para rotaciones aleatorias\n",
    "    width_shift_range=0.3,  # Rango para traslaciones horizontales aleatorias\n",
    "    height_shift_range=0.3,  # Rango para traslaciones verticales aleatorias\n",
    "    shear_range=0.3,  # Rango para cortes (shearing) aleatorios\n",
    "    zoom_range=0.3,  # Rango para zoom aleatorio\n",
    "    horizontal_flip=True,  # Volteo horizontal aleatorio\n",
    "    vertical_flip=True,  # Volteo vertical aleatorio\n",
    "    fill_mode='nearest'  # Estrategia para llenar píxeles fuera de los límites después de una transformación\n",
    ")\n",
    "\n",
    "# Crear un generador de lotes de imágenes aumentadas para el conjunto de entrenamiento\n",
    "augmented_train_generator = datagen.flow(X_train, y_train_one_hot, batch_size=16)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=input_shape, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.10))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(11, kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='RMSProp',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8040e22-09ba-4488-a3ba-44e91d744669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train_one_hot, batch_size=32, epochs=60, validation_data=(X_test, y_test_one_hot), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b04057-231f-434d-9838-86e6b1afaf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(augmented_train_generator, epochs=60, validation_data=(X_test, y_test_one_hot), callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170ed02-b08d-4e84-9007-f910f7d0cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6585df-05a3-401d-8cee-7302e2d55c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_species = label_encoder.classes_[predicted_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237318c-4b36-4a6c-903e-2c1a1f864b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('predictionsTrained11.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['file', 'species']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for filename, species in zip(test_labels, predicted_species):\n",
    "        writer.writerow({'file': filename, 'species': species})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0cf80-d9e7-45e3-9cfc-4a2176e30e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
